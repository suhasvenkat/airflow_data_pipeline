Airflow Data Pipeline â€“ CSV to PostgreSQL
ğŸ“Œ Project Overview

This project is a beginner-friendly Apache Airflow ETL pipeline that reads data from CSV files, performs basic data cleaning and transformation using Python, and loads the processed data into a PostgreSQL database.

The goal of this project is to understand how Airflow, Python, Docker, and PostgreSQL work together in a real data engineering pipeline.

ğŸ› ï¸ Tech Stack

Apache Airflow (Astro Runtime)

Python (Pandas, SQLAlchemy)

PostgreSQL

Docker

pgAdmin

ğŸ“‚ Project Structure
airflow_data_pipeline/
â”œâ”€â”€ dags/                     # Airflow DAGs
â”‚   â””â”€â”€ load_excel_to_postgres.py
â”œâ”€â”€ include/
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ building_metadata.csv
â”‚       â””â”€â”€ wther.csv
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ packages.txt
â”œâ”€â”€ airflow_settings.yaml
â”œâ”€â”€ config.yaml
â””â”€â”€ README.md
ğŸ”„ Pipeline Workflow

Extract

Read CSV files from include/data

Transform

Standardize column names

Handle NULL values

Remove duplicates

Perform basic feature engineering

Load

Load cleaned data into PostgreSQL tables:

building

weather

Orchestration

Managed and scheduled using Apache Airflow

â–¶ï¸ How to Run the Project
1ï¸âƒ£ Start Airflow
astro dev start
2ï¸âƒ£ Open Airflow UI
http://localhost:8080
3ï¸âƒ£ Trigger the DAG

DAG name: csv_to_postgres_etl

Trigger manually from the Airflow UI

ğŸ§ª Verify Output

You can verify the tables using pgAdmin or psql:

SELECT COUNT(*) FROM building;
SELECT COUNT(*) FROM weather;
âœ… Features Implemented

Dockerized Airflow environment

CSV to PostgreSQL ETL pipeline

Data cleaning and transformation using Pandas

PostgreSQL integration using Airflow hooks

Manual DAG execution

ğŸš€ Future Improvements

Incremental data loading

TaskFlow API implementation

Data quality checks

Logging and monitoring

Error handling and retries

ğŸ‘¤ Author

Suhas Venkat

Beginner Data Engineer | Learning Apache Airflow & Data Engineering